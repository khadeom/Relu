{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khadeom/Relu/blob/main/web_Scrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNSv349TBGe1"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import json\n",
        "\n",
        "\n",
        "amz_product =[]\n",
        "data = pd.read_csv('/content/Amazon Scraping - Sheet1.csv')\n",
        "# print(data.head)\n",
        "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0','Accept-Language': 'en-US, en;q=0.5'}\n",
        "for i, j in zip(data['Asin'] ,data['country']):\n",
        "  product={}\n",
        "  i=i.strip()\n",
        "  if i[-1] == \"X\":\n",
        "\n",
        "    print(f\"URL https://www.amazon.{j}/dp/{i}\")\n",
        "\n",
        "    time.sleep(0.5 *4)\n",
        "    webpage = requests.get(f\"https://www.amazon.{j}/dp/{i}\", headers=headers) \n",
        "    soup = BeautifulSoup(webpage.content,'lxml')\n",
        "    #ProductTitle\n",
        "    try:\n",
        "      title  = soup.find(\"span\",attrs ={'id':'productTitle'})\n",
        "\n",
        "      title_value = title.string\n",
        "      title_string = title_value.strip().replace(',','')\n",
        "    except:\n",
        "      title_string =\"NA\"\n",
        "    print(\"product Title = \", title_string)\n",
        "    product[\"Product Title\"]  =title_string\n",
        "    # k=json.dumps([title_string])\n",
        "    #Product Image\n",
        "    try:\n",
        "      div=soup.find('div',{\"id\":\"img-canvas\"})\n",
        "      # print(div.find('img').attrs['src'])\n",
        "      img_url=div.find('img').attrs['src']\n",
        "    except AttributeError:\n",
        "      img_url = \"NA\"\n",
        "      # print(\"NA\")\n",
        "    # k=json.dumps([img_url])\n",
        "\n",
        "    product[\"Product Image URL\"] = img_url\n",
        "    print(\"Product Image URL\",img_url)\n",
        "    #Product Price\n",
        "    try:\n",
        "      price = soup.find(\"span\", attrs ={'id': 'price'}).string.strip()\n",
        "\n",
        "    except AttributeError:\n",
        "      price = \"NA\"\n",
        "    k=json.dumps([price])\n",
        "\n",
        "    # print(\"Price is :\",price)\n",
        "    div = soup.find('div',{\"class\":\"tmmSwatches\"})\n",
        "    if price ==\"NA\":\n",
        "      try:\n",
        "        price = div.findAll(\"span\", {\"class\": \"a-color-base\"})\n",
        "        # print(price)\n",
        "        if j==\"de\":\n",
        "          for i in price:\n",
        "            if i.text!=None:\n",
        "              price=i.text.strip()\n",
        "              break\n",
        "        elif j ==\"fr\":\n",
        "          price=price[-1].text.strip()\n",
        "\n",
        "      except Exception as e:\n",
        "        price = \"NA\"\n",
        "    # print(\"Price from second method is\",price)\n",
        "    k=json.dumps([price])\n",
        "\n",
        "    \n",
        "    if price ==\"NA\":\n",
        "\n",
        "      try:\n",
        "        price = div.find(\"span\", {\"class\": \"a-size-base a-color-price a-color-price\"})\n",
        "        # print(price.string)\n",
        "        price=price.text.strip()\n",
        "        # print(2,price)\n",
        "      except AttributeError:\n",
        "        price = \"NA\"\n",
        "    k=json.dumps([price])\n",
        "    \n",
        "\n",
        "    product[\"Price of the Product\"] = price\n",
        "    # j= json.dumps(product)\n",
        "    print(\"price is\",price)\n",
        "\n",
        "    #Product Discription\n",
        "    try:\n",
        "\n",
        "      div = soup.find('div',{\"class\":\"a-expander-content a-expander-partial-collapse-content\"})\n",
        "      productdetails =div.find(\"span\").string.strip()\n",
        "      \n",
        "      \n",
        "    except AttributeError:\n",
        "      productdetails=\"NA\"\n",
        "    product[\"Product DetailsL\"] = productdetails\n",
        "    print(productdetails)\n",
        "\n",
        "    amz_product.append(product)\n",
        "\n",
        "\n",
        "#saving to json file\n",
        "with open(\"Product_Info.json\", \"w\") as outfile:\n",
        "    json.dump(amz_product, outfile)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "web Scrapping.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}